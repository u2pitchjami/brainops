import logging
import os
import re
import shutil
from difflib import SequenceMatcher
from pathlib import Path

from brainops.obsidian_scripts.handlers.header.header_utils import hash_source
from brainops.obsidian_scripts.handlers.sql.db_connection import get_db_connection
from brainops.obsidian_scripts.handlers.sql.db_get_linked_notes_utils import (
    get_new_note_test_metadata,
)
from brainops.obsidian_scripts.handlers.sql.db_utils import safe_execute
from brainops.obsidian_scripts.handlers.utils.files import hash_file_content
from brainops.obsidian_scripts.handlers.utils.paths import ensure_folder_exists

# setup_logger("db_notes_utils", logging.DEBUG)
logger = logging.getLogger("db_notes_utils")


def link_notes_parent_child(incoming_note_id, yaml_note_id):
    """
    Lie une note archive √† sa note synth√®se via `parent_id` et vice- versa.
    """
    conn = get_db_connection()
    if not conn:
        return None
    cursor = conn.cursor()

    try:
        # üîó Mise √† jour des parent_id dans les deux sens
        cursor.execute(
            "UPDATE obsidian_notes SET parent_id = %s WHERE id = %s",
            (yaml_note_id, incoming_note_id),
        )
        cursor.execute(
            "UPDATE obsidian_notes SET parent_id = %s WHERE id = %s",
            (incoming_note_id, yaml_note_id),
        )

        conn.commit()  # ‚úÖ üî• IMPORTANT : On commit avant de fermer la connexion
        logger.info(
            f"üîó [INFO] Liens parent_id cr√©√©s : Archive {incoming_note_id} ‚Üî Synth√®se {yaml_note_id}"
        )

    except Exception as e:
        logger.error(f"‚ùå [ERROR] Impossible d'ajouter les liens parent_id : {e}")
        conn.rollback()  # üî• Annule les modifs en cas d'erreur
    finally:
        cursor.close()  # üî• Toujours fermer le curseur
        conn.close()  # üî• Ferme la connexion proprement


def check_synthesis_and_trigger_archive(note_id, dest_path):
    """
    Si une `synthesis` est modifi√©e, force un recheck de l'archive associ√©e.
    """
    from brainops.obsidian_scripts.handlers.process.headers import add_metadata_to_yaml

    conn = get_db_connection()
    if not conn:
        return
    cursor = conn.cursor()

    try:
        # üîç 1. R√©cup√©rer le chemin de la synthesis
        cursor.execute("SELECT file_path FROM obsidian_notes WHERE id = %s", (note_id,))
        synthesis_path = Path(cursor.fetchone()[0])

        # üîç 2. Extraire le nom de base
        synthesis_name = synthesis_path.stem  # ex : '2025-03-22 - Rapport X'
        archive_name = f"{synthesis_name} (archive).md"
        new_archive_path = synthesis_path.with_name(archive_name)

        # üîç 3. Comparer avec le nom actuel de l'archive
        cursor.execute(
            "SELECT id, file_path FROM obsidian_notes WHERE parent_id = %s AND status = 'archive'",
            (note_id,),
        )
        archive_result = cursor.fetchone()

        if archive_result:
            archive_id, current_archive_path = archive_result
            current_archive_path = Path(current_archive_path)

            # R√©cup√©rer le dossier de la synth√®se
            synthesis_folder = os.path.dirname(dest_path)
            synthesis_folder = Path(synthesis_folder)

            # Nom du fichier de la synth√®se
            synthesis_name = synthesis_path.stem

            # Cr√©er le dossier Archives s'il n'existe pas
            archive_folder = synthesis_folder / "Archives"
            ensure_folder_exists(archive_folder)

            # Nom du fichier de l'archive
            archive_name = f"{synthesis_name} (archive).md"
            new_archive_path = (
                archive_folder / archive_name
            )  # Nouvelle archive dans le dossier "Archives"

            # Si l'archive doit √™tre d√©plac√©e et renomm√©e
            if current_archive_path != new_archive_path:
                logger.info(
                    f"[SYNC] D√©placement et renommage archive : {current_archive_path} ‚Üí {new_archive_path}"
                )
                if new_archive_path.exists():
                    logger.warning(
                        f"[WARN] Fichier {new_archive_path} existe d√©j√†, d√©placement annul√©."
                    )
                else:
                    shutil.move(
                        str(current_archive_path), str(new_archive_path)
                    )  # D√©placement r√©el du fichier avec shutil.move()
                    cursor.execute(
                        "UPDATE obsidian_notes SET file_path = %s WHERE id = %s",
                        (str(new_archive_path), archive_id),
                    )
                    conn.commit()

            # üîÅ Mise √† jour YAML
            add_metadata_to_yaml(
                note_id=archive_id,
                filepath=new_archive_path,
                status="archive",
                synthesis_id=note_id,
            )

        else:
            logger.warning(f"[WARN] Aucune archive trouv√©e pour la synth√®se {note_id}")

    except Exception as e:
        logger.error(
            f"‚ùå [ERROR] Erreur lors de la v√©rification de la synthesis {note_id} : {e}"
        )
    finally:
        cursor.close()
        conn.close()


def file_path_exists_in_db(file_path, src_path=None):
    """
    V√©rifie si un file_path ou src_path existe dans la table obsidian_notes.

    Retourne le note_id si trouv√©, sinon None.
    """
    logger.debug("[DEBUG] entr√©e file_path_exists_in_db")
    logger.debug(f"file_path : {file_path}")
    logger.debug(f"src_path : {src_path}")

    conn = get_db_connection()
    if not conn:
        return None

    try:
        cursor = conn.cursor()

        paths_to_check = []
        if src_path:
            paths_to_check.append(str(src_path))
        paths_to_check.append(str(file_path))

        for path in paths_to_check:
            result = safe_execute(
                cursor,
                "SELECT id FROM obsidian_notes WHERE file_path = %s LIMIT 1",
                (path,),
            ).fetchone()
            logger.debug(f"[DEBUG] file_path_exists_in_db, result for {path}: {result}")
            if result:
                return result[0]

        return None

    except Exception as err:
        logger.error(f"[DB ERROR] {err}")
        return None

    finally:
        cursor.close()
        conn.close()


def check_duplicate(
    note_id: int, file_path: str, threshold: float = 0.9
) -> tuple[bool, list[dict]]:
    """
    V√©rifie s'il existe une note avec un titre ou un contenu similaire (hash source ou fichier).
    """
    logger.debug(f"[DUPLICATE] D√©but v√©rification duplicata pour note_id={note_id}")

    try:
        # üîç R√©cup√©ration des m√©tadonn√©es de la note
        title, source, author, _ = get_new_note_test_metadata(note_id)
        source_hash = hash_source(source)
        content_hash = hash_file_content(file_path)

        conn = get_db_connection()
        if not conn:
            return False, []

        cursor = conn.cursor()
        matches = []
        seen_ids = set()

        # üî° Fuzzy match sur le titre
        title_cleaned = clean_title(title)
        rows = safe_execute(
            cursor,
            "SELECT id, title FROM obsidian_notes WHERE status = %s",
            ("archive",),
        ).fetchall()
        for existing_id, existing_title in rows:
            similarity = SequenceMatcher(None, title_cleaned, existing_title).ratio()
            if similarity >= threshold:
                if existing_id not in seen_ids:
                    matches.append(
                        {
                            "id": existing_id,
                            "title": existing_title,
                            "similarity": round(similarity, 3),
                            "match_type": "title",
                        }
                    )
                    seen_ids.add(existing_id)

        # üîê Match sur le hash de source
        cursor.execute(
            "SELECT id, title FROM obsidian_notes WHERE status = %s AND source_hash = %s",
            ("archive", source_hash),
        )
        for row in cursor.fetchall():
            if row[0] not in seen_ids:
                matches.append(
                    {
                        "id": row[0],
                        "title": row[1],
                        "similarity": 1.0,
                        "match_type": "source_hash",
                    }
                )
                seen_ids.add(row[0])

        # üìÑ Match sur le hash de contenu (fichier)
        cursor.execute(
            "SELECT id, title FROM obsidian_notes WHERE status = %s AND content_hash = %s",
            ("archive", content_hash),
        )
        for row in cursor.fetchall():
            if row[0] not in seen_ids:
                matches.append(
                    {
                        "id": row[0],
                        "title": row[1],
                        "similarity": 1.0,
                        "match_type": "content_hash",
                    }
                )
                seen_ids.add(row[0])

        if matches:
            logger.info(
                f"[DUPLICATE] {len(matches)} doublon(s) d√©tect√©(s) pour note_id={note_id}"
            )
            return True, matches

        logger.debug(f"[DUPLICATE] Aucun doublon trouv√© pour note_id={note_id}")
        return False, []

    except Exception as e:
        logger.error(f"[ERROR] check_duplicate({note_id}) : {e}")
        return False, []


def clean_title(title):
    # Supprimer les chiffres de date et les underscores pour une meilleure comparaison
    return re.sub(r"^\d{6}_?", "", title.replace("_", " ")).lower()
