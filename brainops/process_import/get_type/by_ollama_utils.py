"""
# handlers/process/get_type.py
"""

from __future__ import annotations

from datetime import datetime
from pathlib import Path
import re

from Levenshtein import ratio

from brainops.models.classification import ClassificationResult
from brainops.models.exceptions import BrainOpsError, ErrCode
from brainops.ollama.ollama_call import call_ollama_with_retry
from brainops.ollama.prompts import PROMPTS
from brainops.process_folders.folders import add_folder
from brainops.process_import.utils.divers import (
    prompt_name_and_model_selection,
)
from brainops.sql.categs.db_dictionary_categ import (
    generate_categ_dictionary,
    generate_optional_subcategories,
    get_categ_id_from_name,
    get_subcateg_from_categ,
)
from brainops.sql.folders.db_folder_utils import (
    get_folder_path_by_id,
)
from brainops.sql.get_linked.db_get_linked_folders_utils import (
    get_category_context_from_folder,
)
from brainops.utils.config import (
    MODEL_GET_TYPE,
    SIMILARITY_WARNINGS_LOG,
    Z_STORAGE_PATH,
)
from brainops.utils.logger import LoggerProtocol, ensure_logger, with_child_logger

# ---------- Parse & nettoyage --------------------------------------------------


def parse_category_response(llama_proposition: str) -> str:
    """
    Extrait "Category/Subcategory" d'une réponse LLM.
    """
    match = re.search(r"([A-Za-z0-9_ ]+)/([A-Za-z0-9_ ]+)", llama_proposition or "")
    if match:
        return f"{match.group(1).strip()}/{match.group(2).strip()}"
    raise BrainOpsError(
        "[METADATA] ❌ Parse Categ KO",
        code=ErrCode.METADATA,
        ctx={"fonction": "parse_category_response", "llama_proposition": llama_proposition},
    )


@with_child_logger
def clean_note_type(parse_category: str, logger: LoggerProtocol | None = None) -> str:
    """
    Nettoyage: guillemets -> off, espaces -> _, interdits -> off, pas de '.' final.
    """
    logger = ensure_logger(logger, __name__)
    clean_str = parse_category.strip().replace('"', "").replace("'", "")
    clean_str = clean_str.replace("\n", "")
    clean_str = clean_str.replace(" ", "_")
    clean_str = re.sub(r'[\:*?"<>|]', "", clean_str)
    clean_str = re.sub(r"\.$", "", clean_str)
    return prep_and_similarity_test(clean_str, logger=logger)


# ---------- Similarité (inchangé) ---------------------------------------------


def find_similar_levenshtein(
    name: str,
    existing_names: list[str],
    threshold_low: float = 0.7,
    entity_type: str = "subcategory",
) -> list[tuple[str, float]]:
    """
    find_similar_levenshtein _summary_

    _extended_summary_

    Args:
        name (str): _description_
        existing_names (list[str]): _description_
        threshold_low (float, optional): _description_. Defaults to 0.7.
        entity_type (str, optional): _description_. Defaults to "subcategory".

    Returns:
        _type_: _description_
    """
    similar: list[tuple[str, float]] = []
    try:
        for existing in existing_names:
            similarity = ratio(name, existing)
            # logger.debug(...) → logger injecté + décorateur dans les call sites
            if similarity >= threshold_low:
                similar.append((existing, similarity))
    except Exception as exc:
        raise BrainOpsError(
            "[METADATA] ❌ Erreur dans la recherche de similarité",
            code=ErrCode.METADATA,
            ctx={"fonction": "find_similar_levenshtein", "name": name},
        ) from exc
    return sorted(similar, key=lambda x: x[1], reverse=True)


@with_child_logger
def prep_and_similarity_test(note_type: str, logger: LoggerProtocol | None = None) -> str:
    logger = ensure_logger(logger, __name__)
    try:
        parts = [p.strip() for p in note_type.split("/", 1)]
        category_name = parts[0]
        subcategory_name = parts[1] if len(parts) == 2 and parts[1] else "unknow"
        if not category_name:
            raise BrainOpsError(
                "[METADATA] ❌ Impossible de parser la proposition Ollama",
                code=ErrCode.METADATA,
                ctx={"fonction": "prep_and_similarity_test", "note_type": note_type},
            )
        list_categ = generate_categ_dictionary(for_similar=True, logger=logger)
        logger.debug(f"list_categ: {list_categ}")
        real_category_name = check_and_handle_similarity(
            category_name, existing_names=list_categ, entity_type="category"
        )
        logger.debug(f"real_category_name: {real_category_name}")
        if subcategory_name is not None and real_category_name:
            cat_id = get_categ_id_from_name(name=real_category_name, logger=logger)
            logger.debug(f"cat_id: {cat_id}")
            subcategs = get_subcateg_from_categ(categ_id=cat_id, logger=logger)
            logger.debug(f"subcategs: {subcategs}")
            real_subcategory_name = check_and_handle_similarity(
                subcategory_name, existing_names=subcategs, entity_type="subcategory"
            )
            logger.debug(f"real_subcategory_name: {real_subcategory_name}")

        return f"{real_category_name}/{real_subcategory_name}"
    except Exception as exc:
        raise BrainOpsError(
            "[METADATA] ❌ Check similarités categ/subcateg KO",
            code=ErrCode.METADATA,
            ctx={
                "fonction": "_classify_with_llm",
                "real_category_name": real_category_name,
                "real_subcategory_name": real_subcategory_name,
            },
        ) from exc


def check_and_handle_similarity(
    name: str,
    existing_names: list[str],
    threshold_low: float = 0.7,
    entity_type: str = "subcategory",
) -> str | None:
    """
    check_and_handle_similarity _summary_

    _extended_summary_

    Args:
        name (str): _description_
        existing_names (list[str]): _description_
        threshold_low (float, optional): _description_. Defaults to 0.7.
        entity_type (str, optional): _description_. Defaults to "subcategory".

    Returns:
        Optional[str]: _description_
    """
    threshold_high = 0.9
    similar = find_similar_levenshtein(name, existing_names, threshold_low, entity_type)
    if similar:
        closest, score = similar[0]
        if score >= threshold_high:
            # Fusion auto
            return closest
        if threshold_low <= score < threshold_high:
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            log_message = (
                f"[{current_time}] Doute sur {entity_type}: '{name}' proche de '{closest}' (score: {score:.2f})\n"
            )
            # On log dans le fichier prévu
            with open(SIMILARITY_WARNINGS_LOG, "a", encoding="utf-8") as log_file:
                log_file.write(log_message)
            return None
    return name


# ---------- Classification & déplacement --------------------------------------


@with_child_logger
def _classify_with_llm(note_id: int, content: str, *, logger: LoggerProtocol | None = None) -> str:
    """
    Construit le prompt et appelle Ollama.

    Retourne la chaîne brute (ex: "Dev/Python").
    """
    logger = ensure_logger(logger, __name__)
    try:
        # dictionnaires pour guider le LLM
        subcateg_dict = generate_optional_subcategories(logger=logger)
        logger.debug("[DEBUG] subcateg_dict _classify_with_llm : %s", subcateg_dict)
        categ_dict = generate_categ_dictionary(logger=logger)
        logger.debug("[DEBUG] categ_dict _classify_with_llm : %s", categ_dict)

        prompt_name, _ = prompt_name_and_model_selection(note_id, key="type", logger=logger)  # note_id pas requis ici
        logger.debug("[DEBUG] prompt_name _classify_with_llm : %s", prompt_name)
        model_ollama = MODEL_GET_TYPE
        prompt = PROMPTS[prompt_name].format(
            categ_dict=categ_dict,
            subcateg_dict=subcateg_dict,
            content=content[:1500],
        )
        logger.debug("[DEBUG] prompt _classify_with_llm : %s", prompt)
        return call_ollama_with_retry(prompt, model_ollama, logger=logger)
    except Exception as exc:
        raise BrainOpsError(
            "[METADATA] ❌ Construction prompt get_type KO",
            code=ErrCode.METADATA,
            ctx={"fonction": "_classify_with_llm", "note_id": note_id},
        ) from exc


@with_child_logger
def _resolve_destination(note_type: str, note_id: int, *, logger: LoggerProtocol | None = None) -> ClassificationResult:
    """
    À partir du note_type "Cat/Sub", calcule ids + dossier cible.
    """
    logger = ensure_logger(logger, __name__)
    try:
        subcat_id = None
        try:
            parts = [p.strip() for p in note_type.split("/", 1)]
            category_name = parts[0]
            subcategory_name = parts[1] if len(parts) == 2 and parts[1] else None
        except Exception as exc:  # pylint: disable=broad-except
            raise BrainOpsError(
                "[METADATA] ❌ Impossible de parser la proposition Ollama",
                code=ErrCode.METADATA,
                ctx={"fonction": "_resolve_destination", "note_id": note_id, "note_type": note_type},
            ) from exc

        categ_path = Path(Z_STORAGE_PATH) / category_name
        logger.debug(f"categ_path: {categ_path}")
        cat_folder_id = add_folder(folder_path=categ_path, logger=logger)
        logger.debug(f"cat_folder_id: {cat_folder_id}")
        if subcategory_name is not None:
            subcateg_path = Path(Z_STORAGE_PATH) / category_name / subcategory_name
            logger.debug(f"subcateg_path: {subcateg_path}")
            sub_folder_id = add_folder(folder_path=subcateg_path, logger=logger)
            logger.debug(f"sub_folder_id: {sub_folder_id}")
            def_path = get_folder_path_by_id(sub_folder_id, logger=logger)
            logger.debug(f"def_path: {def_path}")
            classification = get_category_context_from_folder(def_path, logger=logger)
            logger.debug(f"classification: {classification}")
        else:
            def_path = get_folder_path_by_id(cat_folder_id, logger=logger)
            classification = get_category_context_from_folder(def_path, logger=logger)

    except Exception as exc:
        raise BrainOpsError(
            "[METADATA] ❌ Impossible d'indentifier une localisation à partir de la proposition Ollama",
            code=ErrCode.METADATA,
            ctx={"fonction": "_resolve_destination", "note_id": note_id, "note_type": note_type},
        ) from exc
    return ClassificationResult(
        category_name=classification.category_name or category_name,
        category_id=classification.category_id,
        subcategory_name=classification.subcategory_name or subcategory_name,
        subcategory_id=classification.subcategory_id or subcat_id,
        folder_id=sub_folder_id or cat_folder_id,
        dest_folder=def_path,
        status="archive",
    )
